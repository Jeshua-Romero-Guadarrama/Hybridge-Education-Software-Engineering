{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación de modelos\n",
    "\n",
    "Hemos construido un modelo. Pero, ¿qué tan bueno es?\n",
    "\n",
    "En esta lección, aprenderemos a usar la validación del modelo para medir la calidad de nuestro modelo. Medir la calidad del modelo es la clave para mejorar nuestros modelos de manera iterativa.\n",
    "\n",
    "## ¿Qué es la validación de modelos?\n",
    "\n",
    "Siempre vamos a querer evaluar casi todos los modelos que construyamos. En la mayoría de las aplicaciones (aunque no en todas), la medida relevante de la calidad del modelo es la precisión predictiva. En otras palabras, ¿las predicciones del modelo estarán cerca de lo que realmente sucede?\n",
    "\n",
    "Muchas personas cometen un gran error al medir la precisión predictiva. Hacen predicciones con sus datos de entrenamiento y comparan esas predicciones con los valores objetivo en los datos de entrenamiento. Veremos el problema con este enfoque y cómo solucionarlo en un momento, pero primero pensemos en cómo lo haríamos.\n",
    "\n",
    "Primero necesitaríamos resumir la calidad del modelo de una manera comprensible. Si comparamos los valores predichos y reales de 10,000 casas, probablemente encontraremos una mezcla de buenas y malas predicciones. Revisar una lista de 10,000 valores predichos y reales sería inútil. Necesitamos resumir esto en una sola métrica.\n",
    "\n",
    "Existen muchas métricas para resumir la calidad del modelo, pero comenzaremos con una llamada Error Absoluto Medio (Mean Absolute Error, también conocido como MAE). Desglosaremos esta métrica comenzando con la última palabra, error.\n",
    "\n",
    "El error de predicción para cada casa es:\n",
    "\n",
    "$$\n",
    "error = real − predicción\n",
    "$$\n",
    "\n",
    "Entonces, si una casa costó 150,000 y predijiste que costaría 100,000, el error es 50,000.\n",
    "\n",
    "Con la métrica MAE, tomamos el valor absoluto de cada error. Esto convierte cada error en un número positivo. Luego tomamos el promedio de esos errores absolutos. Esta es nuestra medida de la calidad del modelo. En lenguaje sencillo, se puede decir:\n",
    "\n",
    "> En promedio, nuestras predicciones están equivocadas por aproximadamente X.\n",
    "\n",
    "Para calcular el MAE, primero necesitamos un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Cargar datos\n",
    "ruta = './data/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(ruta) \n",
    "\n",
    "# Quitar nulos\n",
    "melbourne_data_filtrada = melbourne_data.dropna(axis=0)\n",
    "\n",
    "# Elegir target\n",
    "y = melbourne_data_filtrada.Price\n",
    "\n",
    "# Elegir features\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "\n",
    "# Crear X\n",
    "X = melbourne_data_filtrada[melbourne_features]\n",
    "\n",
    "\n",
    "# Definir modelo\n",
    "modelo = DecisionTreeRegressor()\n",
    "\n",
    "# Ajustar modelo\n",
    "modelo.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestro modelo y ahora podemos calcular el MAE. Para esto utilizaremos también `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicciones = modelo.predict(X)\n",
    "mean_absolute_error(y, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Problema con los puntajes \"dentro de la muestra\"\n",
    "\n",
    "La medida que acabamos de calcular puede llamarse un puntaje \"dentro de la muestra\". Usamos una sola \"muestra\" de casas tanto para construir el modelo como para evaluarlo. Esto está mal. Veamos por qué.\n",
    "\n",
    "Imaginemos que en el mercado inmobiliario el color de la puerta no está relacionado con el precio de la casa.\n",
    "\n",
    "Sin embargo, en la muestra de datos que usamos para construir el modelo, todas las casas con puertas verdes eran muy caras. El trabajo del modelo es encontrar patrones que predigan los precios de las casas, así que verá este patrón y siempre predecirá precios altos para las casas con puertas verdes.\n",
    "\n",
    "Dado que este patrón se derivó de los datos de entrenamiento, el modelo parecerá preciso en los datos de entrenamiento.\n",
    "\n",
    "Pero si este patrón no se mantiene cuando el modelo ve nuevos datos, el modelo sería muy impreciso cuando se use en la práctica.\n",
    "\n",
    "Dado que el valor práctico de los modelos proviene de hacer predicciones sobre nuevos datos, medimos el rendimiento en datos que no se usaron para construir el modelo. La forma más sencilla de hacer esto es excluir algunos datos del proceso de construcción del modelo y luego usarlos para probar la precisión del modelo en datos que no ha visto antes. Estos datos se llaman datos de validación.\n",
    "\n",
    "## Partiendo los datos\n",
    "Vamos a dividir nuestros datos en 2 subconjuntos: set de entrenamiento y set de pruebas.\n",
    "\n",
    "`scikit-learn` tiene una función llamada `train_test_split` para dividir los datos en estas dos partes. Usaremos algunos de esos datos como datos de entrenamiento para ajustar el modelo, y usaremos los otros datos como datos de validación para calcular el error absoluto medio (`mean_absolute_error`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos los datos en datos de entrenamiento y de validación, tanto para las características como para el objetivo\n",
    "\n",
    "Esta división se basa en un generador de números aleatorios. Por lo tanto, podemos darle un `random_state` para que siempre que corramos nuestro código, tengamamos exactamente los mismos sets de entrenamiento y de pruebas.\n",
    "\n",
    "La función `train_test_split` recibe 2 argumentos y 1 opcional. El primer argumento es el dataframe que contiene los features, y el segundo argumento contiene los precios (targets). \n",
    "\n",
    "La función nos regresará 4 conjuntos de datos. 2 para entrenar y 2 para probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definamos nuestro modelo nuevamento y ajustémoslo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = DecisionTreeRegressor()\n",
    "\n",
    "# Ajustar únicamente con datos de entrenamiento\n",
    "modelo.fit(train_X, train_y)\n",
    "\n",
    "# obtener predicciones\n",
    "val_predictions = modelo.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡¿Ves la diferencia?!**\n",
    "\n",
    "Cuando validamos nuestro modelo con los mismos datos con los que lo entrenamos, obtubimos un error de alrededor 500 dólares, pero ahora tenemos un error de 263,515 dólares!\n",
    "\n",
    "---\n",
    "\n",
    "Ésta es la diferencia entre un modelo que es casi exactamente correcto y uno que es inutilizable para la mayoría de los propósitos prácticos. Como punto de referencia, el valor promedio de una casa en los datos de validación es de 1.1 millones de dólares. Por lo tanto, el error en los nuevos datos es aproximadamente una cuarta parte del valor promedio de la casa.\n",
    "\n",
    "Hay muchas maneras de mejorar este modelo, como experimentar para encontrar mejores características o diferentes tipos de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
